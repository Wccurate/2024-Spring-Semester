# 计算机体系结构

## 第一章 导论

计算机系统的组成1：运算器，控制器，存储器，输入设别，输出设备五部分 I/O-CPU-M/S（Memory storage）

组成2:硬件，软件			组成3:人员，数据，设备

冯诺依曼架构的特点：==存储程序==，运算器为中心，集中控制

现代对冯诺依曼架构的改进：存储程序不变，存储器为核心，总线结构，分散控制

硬件发展史：电子管-》晶体管-〉集成电路（LSI）-》大规模集成电路（VLSI）

MIPS=Fz*IPC

虚拟计算机：只针对观察者所展示出的计算机

M0-M7从硬联逻辑到系统分析

0-1硬件实现，3-6软件实现（==虚拟机==）

计算机系统结构的定义1（==使用者==）：是程序设计者所看到的计算机属性（==概念性结构==和==功能特性==）

透明性：1.==确实存在== 2.==无法监测和设置==

定义2（==设计者==）:研究软硬件功能分配和对软硬件洁面的确定

计算机==组成==：计算机的逻辑实现，个部分之间的关系

计算机==实现==： 硬件的物理实现

| 计算机系统结构   | 计算机组成 | 计算机实现 |
| ---------------- | ---------- | ---------- |
| 确定软硬件分界线 | 逻辑实现   | 物理实现   |

计算机系统的特性：计算机等级（大中小型），系列机（相同的系统结构，组成和实现不同），软件兼容（目标程序在相同体系结构的机器上可以运行，向上兼容，向后兼容）

程序移植时的两种方法：

模拟方法：将目标代码（机器语言）继续翻译成宿主机的机器语言进行运行（全部使用软件，宿主机，虚拟机）

仿真方法：将目标代码（机器语言）使用宿主机的微程序进行解释（软硬件混合，宿主机，目标机）

Amdahl Rule

$Accelerate~Rate=\frac{改进后性能}{改进前性能}-\frac{改进前时间}{改进后时间}$
$F_e=\frac{改进部分占的时间}{改进前整个任务占的时间}$                      $S_e=\frac{改进前改进部分用时}{改进后改进部分的用时}$

$S_n=\frac{1}{(1-F_e)+\frac{F_e}{S_e}}$

计算某一部分的用时： $T_n=CPI(Cycle~per~Instruction)*IC(Total~Instruction~Count)*T(Time~per~Instruction)$

多核Amdahl



计算设计：自上而下（==从用户需求考虑==），自下而上（==从已有硬件考虑==），中间开始（==确定软硬件的分界面==）

计算机系统结构的分类

福林分类法：指令流，数据流，多倍性（SISD，SIMD，MISD，MIMD）

## 第二章 处理器机器相关技术

CPU三个功能部件：控制器，运算器，寄存器

数据表示：能直接由硬件识别的数据格式（向量，图，树等）

指令格式优化：定长编码，Huffman编码，拓展编码

信息熵-》理论最小的平均编码长度

CISC：复杂指令集，x86，

RISC：精简指令集，MIPS，ARM，指令条数少

RISC-V：开源，

超线程：CPU的虚拟化

SIMD指令集和数据并行：在将一个寄存器划分为多个部分来实现单指令和多数据

GPU和CPU的区别：1.CPU通用，几十个核心，GPU面对高并发任务，几百个几千个核心，核心小；2.CPU大部分为控制电路，GPU大部分为计算核心（遵循SIMD模型）；

GPU==基本运算单元==是流处理器（==SP==）

GPU==执行指令的基本单位==是流多处理器（==SM==）由多个SP，寄存器，缓存和指令控制单元

$GPU=n\times MP（n\times SP + n\times Shared~L_1~cache +n\times Registers）+n\times Shared~L_2~caches+n\times Registers$

GPU编程：网格-》线程块-〉线程	核函数在GPU上执行，主机代码在CPU上执行，函数有：malloc，memcopy，free等		网格-》线程块（一个线程块只能分给一个SM，一个SM可以分到多个线程块，取决于SM的资源是够有盈余）-〉线程束（32个线程）-》线程（一个线程由一个CUDA Core（SP）执行）

## 第三章 存储系统结构

程序的定位（Storage-》memory）：加基址方式（==静态定位==，==动态定位==），地址映像方式（==段式管理，模块化，段表管理==，==页式管理，==）

映像方法：全相联映像（虚存页面可以放到实存的任何位置），直接映像（将虚存按实存地址分页），组相连映像（虚存分块，块中分组，实存也分组，不同块的相同组只能存放到实存的特定位置，组内的页面在实存的组范围内可以直接相连），段相联映像（段全相联，段内页面直接相联）

替换算法：RAND，FIFO，LRU，OPT

堆栈型替换算法；$B_t(n)$表示实存大小为n的时候对于一个页面流A，替换算法在t时刻实存中含有的页面数，$L_t$是在前t时间内见过的页面号的set

充要条件满足:$B_t(n) \subset B_t(n+1),~n<L_t$	$B_t(n)=B_t(n+1),~n>=L_t$

堆栈型算法：==LRU==，==OPT==

并行主存系统：





## 第五章 并行处理机

并行性：在同一时刻或==同一时间间隔==完成两种以上的工作（并行性= ==同时性==+==并发性==）

并行性的等级：

+ ==执行角度看==

  + 指令内部并行

  + 指令间并行

  + 任务级或者过程级的并行

  + 作业级或程序级并行

+ ==数据角度看==

  + 字串位串，无并行性
  + 字串位并
  + 字并位串
  + 字并串并

提高并行性的措施：

+ 时间重叠
+ 资源重复
+ 资源共享

并行处理机的定义：称为SIMD计算机，一个控制器（CU），多个处理单元（PE），









# 考试

## 简答题

（1）MPI函数的作用：

+ mpi_init()初始化MPI环境
+ mpi_comm_size()获取进程的数量
+ mpi_comm_rank()获取本进程进程号
+ mpi_finalize()退出mpi环境
+ mpi_send（）点对点发送数据
+ mpi_recieve（）点对点接受数据
+ mpi_bcast（）广播
+ mpi_reduction（）规约
+ mpi_gather（）收集
+ mpi_scatter（）散发
+ mpi_barrier（）同步

（2）ISA分类：

+ RISC：精简指令集，指令复杂，条数多，对硬件的设计要求高，80%的指令没有被经常使用，使用最少的指令条数来完成任务
+ CISC：复杂指令集，指令简单，只有大部分的常用指令，对硬件的设计要求低，指令条数少，但是完成相应的任务可能需要更多的时钟周期

（3）CUDA：

+ 定义：计算统一架构设备，面向通用计算架构的GPU的并行计算平台和编程模型，进行通用数值的计算

+ 层次结构：

+ $GPU=n\times MP（n\times SP + n\times Shared~L_1~cache +n\times Registers）+n\times Shared~L_2~caches+n\times Registers$

  GPU编程：网格-》线程块-〉线程	核函数在GPU上执行，主机代码在CPU上执行，函数有：malloc，memcopy，free等		网格-》线程块（一个线程块只能分给一个SM，一个SM可以分到多个线程块，取决于SM的资源是够有盈余）-〉线程束（32个线程）-》线程（一个线程由一个CUDA Core（SP）执行）

（4）并行处理机

+ 概念：也称作SIMD计算机，一个控制器（CU）控制多个处理单元（PE），构成阵列，也称作阵列处理机。CU分配同一指令堆不同数据进行操作。
+ 并行等级：
  + 执行层面：==指令内并行==，==指令间并行==，==任务级或过程级并行==，==作业或者程序级并行==
  + 数据层面：==字串位串==，==字串位并==，==字并位串==，==字并位并==

（5）虚拟存储器

+ 虚拟存储器与Cache的相似性：

  - **命中率和替换算法**：虚拟存储器和Cache都依赖命中率来衡量效率，并使用替换算法（如LRU）优化性能。

  - **映射关系**：两者都使用映射机制将大范围地址映射到较小存储空间，Cache使用直接映射、组相联映射或全相联映射，虚拟存储器使用页表。

  - **性能**：通过减少慢速存储器访问来提高系统性能。

+ 虚拟存储器的命中率与主存命中率

  - **虚拟存储器的命中率**：指在虚拟地址访问中直接找到数据的比例，未命中时需从磁盘加载。

  - **主存命中率**：指在主存中找到数据的比例，未命中时需访问磁盘。

  - 条件变化与命中率影响：
    - 增加分配给进程的主存大小，可以提高虚拟存储器的命中率。
    - 增大页面大小，可能减少页表开销，但如果页面过大，未命中的代价也会增加。
    - 优化替换算法（如从FIFO改为LRU），可以提高命中率。

+ 分配给进程的主存大小

  - **描述**：操作系统按需为进程分配物理内存页框，大小取决于系统可用内存和进程需求。

  - **条件变化与命中率影响**：增加分配的主存大小，虚拟存储器命中率会提高，减少换出到磁盘的频率。

+ 页面大小

  - **描述**：页面大小是虚拟存储器的最小管理单元，通常为4KB、8KB或更大。

  - 条件变化与命中率影响：
    - 较大页面减少页表开销，但可能增加内存碎片，未命中的代价也会增加。
    - 较小页面减少内存碎片，但增加页表管理开销，可能会稍微降低命中率。

+ 替换算法
  - 描述：替换算法决定内存不足时换出的页面。常用算法包括：
    - **LRU**：最近最少使用
    - **FIFO**：先进先出
    - **LFU**：最少使用
    - **Clock**：改进的FIFO算法

- **条件变化与命中率影响**：使用更有效的替换算法（如LRU）可以提高命中率，减少不必要的页面换出。

（6）流水线的特点：

+ 划分为若干互有联系的子过程（功能段），每个功能段由专门的功能部件实现
+ 实现功能段所需的时间应该尽可能相等，避免产生断流和瓶颈
+ 需要一段“通过时间”来让流水线变得稳定
+ 指令流不能顺序执行时会导致断流，再形成流水，需要一段时间，不能经常断流，否则效率极低
+ 流水线技术适用于大量重复的程序过程，只有输入端能连续的提供服务，流水线效率才能得到充分发挥









# 杂项

集群计算机可以分为三类：

+ 高可用
+ 负载均衡
+ 高性能计算

云计算的定义：分布式处理，并行处理，网格计算

云计算特点：

+ 超大规模和廉价性
+ 虚拟化
+ 高可靠性
+ 通用性
+ 高可拓展性
+ 按需服务

冯诺依曼架构的特点：==存储程序==，运算器为中心，集中控制

现代对冯诺依曼架构的改进：存储程序不变，存储器为核心，总线结构，分散控制

系统结构的定义：程序设计者看到的计算机属性概念性功能和功能特性

透明性：确实存在，无法检测

计算机组成：逻辑顺序

计算机实现：物理实现

模拟与仿真：模拟（虚拟机，宿主机）

并行处理机：SIMD

多处理机系统：MIMD

无阻塞交叉开关：不断增加总线数目时，使得每个存储器模块都有自己单独可用的通路，这种互联网络称为无障碍交叉开关

多处理机系统的cache一致方法：静态检验法，动态检验法（==写回法和写直达法不可用==）



